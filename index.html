<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<link rel="stylesheet" type="text/css" href="style.css">
		<title>Lucas Lehnert</title>
	</head>
	<body>
		<div class="con-all">
		<div class="pic-l">
			<img class="scaled" src="images/ProfilePictureLucas.png"/>
		</div>

		<div class="div-650">
			<p>
				<h1>Lucas Lehnert</h1>
				<h3>PhD Student in Computer Science</h3>
				<p>
					<img src="images/Email.png" style="height:16px; position: relative; top: 5px;" alt="lucas_lehnert at brown dot edu" border="0" />
					<a href="https://www.linkedin.com/pub/lucas-lehnert/8b/413/a" target="_blank">
						<img src="https://static.licdn.com/scds/common/u/img/webpromo/btn_in_20x15.png" style="width:20px; height:15px; position: relative; top: 2px;" alt="View Lucas Lehnert's LinkedIn profile" border="0" />
					</a>
					<a href="https://github.com/lucaslehnert" target="_blank">
						<img src="icons/GitHub-Mark-32px.png" style="width:16px; height:16px; position: relative; top: 2px;" alt="Link to Lucas Lehnert's github" border="0" />
					</a>
				</p>
			</p>
		</div>

		<div class="div-650">
			<p>
				Since fall 2016 I am a PhD student working with <a href="http://cs.brown.edu/~mlittman/" target="_blank">Michael L. Littman</a> and <a href="http://ski.cog.brown.edu/" target="_blank">Michael J. Frank</a> at Brown University.
				Before joining Brown University I obtained a Master's and Bachelor's degree in computer science from McGill University under the supervision of <a href="http://cs.mcgill.ca/~dprecup" target="_blank">Doina Precup</a>.
			</p>
		</div>

		<div class="div-800">
			<p>
				I am interested in developing algorithms that learn to solve a wide variety of problems without having to adapt the algorithm to the task at hand.
				Most of my work falls into the categories of reinforcement learning, artificial intelligence, and machine learning. 
				During my undergraduate studies, I also worked on projects in computer vision, signal processing, and robotics.
			</p>
		</div>

		<div class="con-row, div-800">
			<h2>Papers</h2>
			<hr/>
		</div>

		<div class="con-row">
			<div class="pic-l">
				<img style="scaled" width=154 src="images/HistogramPredictive.png"/>
			</div>
			<div class="div-650">
				<p>Lucas Lehnert, Michael L. Littman, and Michael J. Frank<br>
					<b><a href="https://www.biorxiv.org/content/10.1101/653493v2" target="_blank">Reward-predictive representations generalize across tasks in reinforcement learning</a></b><br>
					<i>bioXiv 653493, doi: <a href="https://doi.org/10.1101/653493" target="_blank">https://doi.org/10.1101/653493</a>, 2020</i>
				</p>
			</div>
		<div>

		<div class="con-row">
			<div class="div-800">
				<hr/>
			</div>
		</div>

		<div class="con-row">
			<div class="pic-l">
				<img style="scaled" width=154 src="images/RewardPredictive.png"/>
			</div>
			<div class="div-650">
				<p>Lucas Lehnert and Michael L. Littman<br>
					<b><a href="https://arxiv.org/pdf/1901.11437.pdf" target="_blank">Successor Features Combine Elements of Model-Free and Model-based Reinforcement Learning</a></b><br>
					<i>arXiv preprint arXiv:1901.11437, 2019</i>
				</p>

				<p>Lucas Lehnert and Michael L. Littman<br>
					<b><a href="https://arxiv.org/pdf/1807.01736.pdf" target="_blank">Transfer with Model Features in Reinforcement Learning</a></b><br>
					<i>Lifelong Learning: A Reinforcement Learning Approach workshop at FAIM, Stockholm, Sweden, 2018</i> [<a href="https://arxiv.org/abs/1807.01736" target="_blank">arXiv</a>]
				</p>
			</div>
		<div>

		<div class="con-row">
			<div class="div-800">
				<hr/>
			</div>
		</div>

		<div class="con-row">
			<div class="pic-l">
				<img style="scaled" width=154 src="images/PACAbstraction.png"/>
			</div>
			<div class="div-650">
				<p>David Abel, Dilip S. Arumugam, Lucas Lehnert, and Michael L. Littman<br>
					<b><a href="http://proceedings.mlr.press/v80/abel18a.html" target="_blank">State Abstractions for Lifelong Reinforcement Learning</a></b><br>
					<i>Proceedings of the 35th International Conference on Machine Learning, PMLR 80:10-19, 2018</i> [<a href="http://proceedings.mlr.press/v80/abel18a/abel18a.pdf" target="_blank">PDF</a>]
				</p>

				<p>David Abel, Dilip Arumugam, Lucas Lehnert, and Michael L. Littman<br>
					<b><a href="https://drive.google.com/file/d/1MrNzgpVXYRlp8xfQ6Qjmxs7UNO5T376g/view" target="_blank">Toward Good Abstractions for Lifelong Learning</a></b><br>
					<i>NIPS workshop on Hierarchical Reinforcement Learning, 2017</i> [<a href="papers/NIPS2017_HRL_abstraction.pdf" target="_blank">PDF</a>]
				</p>
			</div>
		<div>

		<div class="con-row">
			<div class="div-800">
				<hr/>
			</div>
		</div>

		<div class="con-row">
			<div class="pic-l">
				<img style="scaled" width=154 src="images/LHP.png"/>
			</div>
			<div class="div-650">
				<p>Lucas Lehnert, Romain Laroche, and Harm van Seijen<br>
					<b><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16388" target="_blank">On Value Function Representation of Long Horizon Problems</a></b><br>
					<i>In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, 2018</i> [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16388/16727" target="_blank">PDF</a>]
				</p>
			</div>
		<div>

		<div class="con-row">
			<div class="div-800">
				<hr/>
			</div>
		</div>

		<div class="con-row">
			<div class="pic-l">
				<img style="scaled" width=154 src="images/SFNav.png"/>
			</div>
			<div class="div-650">
				<p>Lucas Lehnert, Stefanie Tellex, and Michael L. Littman<br>
					<b><a href="https://drive.google.com/file/d/0B9dqzboiV5u-dUlLSmRxTzdhXzQ/view" target="_blank">Advantages and Limitations of Using Successor Features for Transfer in Reinforcement Learning</a></b><br>
					<i>Lifelong  Learning:  A Reinforcement Learning Approach workshop @ICML, Sydney,  Australia,  2017</i> [<a href="https://arxiv.org/pdf/1708.00102.pdf" target="_blank">arXiv</a>]<br>
					<b>Best Student Paper Award</b>
				</p>
			</div>
		<div>

		<div class="con-row">
			<div class="div-800">
				<hr/>
			</div>
		</div>

		<div class="con-row">
			<div class="pic-l">
				<img style="scaled" width=154 src="images/MSPBE.png"/>
			</div>
			<div class="div-650">
				<p>Lucas Lehnert and Doina Precup<br>
					<b><a href="https://ewrl.files.wordpress.com/2016/11/ewrl13-2016-submission_24.pdf" target="_blank">Using Policy Gradients to Account for Changes in Behavior Policies Under Off-policy Control</a></b><br>
					<i>The 13th European Workshop on Reinforcement Learning (EWRL 2016)</i> [<a href="papers/ewrl13-2016-submission_24.pdf" target="_blank">pdf</a>]
				</p>

				<p>Lucas Lehnert and Doina Precup<br>
					<b><a href="https://arxiv.org/pdf/1512.04105v1.pdf" target="_blank">Policy Gradient Methods for Off-policy Control</a></b><br>
					<i>arXiv: 1512.04105 [cs.AI], Dec. 13, 2015</i> 
				</p>

				<p>Lucas Lehnert<br>
					<b><a href="http://digitool.library.mcgill.ca/R/-?func=dbin-jump-full&object_id=145481&silo_library=GEN01" target="_blank">Off-policy control under changing behaviour</a></b><br>
					<i>Master of Science Thesis, McGill University, 2017</i> [<a href="papers/MScThesis.pdf" target="_blank">pdf</a>]
				</p>
			</div>
		<div>

		<div class="con-row">
			<div class="div-800">
				<hr/>
			</div>
		</div>

		<div class="con-row">
			<div class="pic-l">
				<img style="scaled" width=154 src="images/RobotPath.png"/>
			</div>
			<div class="div-650">
				<p>
					Lucas Lehnert and Doina Precup<br>
					<b><a href="http://www.ias.informatik.tu-darmstadt.de/uploads/ALR2014/Lehnert_ALR2014.pdf" target="_blank">Building a Curious Robot for Mapping</a></b><br>
					<i>Autonomously Learning Robots workshop (ALR 2014), NIPS 2014</i> [<a href="papers/Lehnert_ALR2014.pdf" target="_blank">pdf</a>]
					<br><br><br>
				</p>
			</div>
		<div>

		<div class="con-row">
			<div class="div-800">
				<hr/>
			</div>
		</div>

		<div class="con-row">
			<div class="pic-l">
				<img style="scaled" width=154 src="images/HeartMRI.png"/>
			</div>
			<div class="div-650">
				<p>
					<p>Arthur Mensch, Emmanuel Piuze, Lucas Lehnert, Adrianus J. Bakermans, Jon Sporring, Gustav J. Strijkers, and Kaleem Siddiqi<br>
					<b><a href="http://link.springer.com/chapter/10.1007/978-3-319-14678-2_9" target="_blank">Connection Forms for Beating the Heart. Statistical Atlases and Computational Models of the Heart - Imaging and Modelling Challenges</a></b><br>
					<i>8896: 83-92. Springer International Publishing, 2014</i>
					</p>
				</p>
			</div>
		<div>

		<div class="con-row" style="padding-top: 50px; padding-bottom: 0px">
			<div class="div-800">
				<h2>Talks</h2>
				<hr/>
			</div>
		</div>

		<div class="con-row">
			<div class="div-800" style="padding-top: 0px;">
				<p>
					<p>Lucas Lehnert. <b><a href="talks/RL_Workshop_SF_ICML_2017.pdf" target="_blank">"Transfer Learning Using Successor State Features"</a></b><br>
					<i>Invited talk at the workshop <a href="https://rllabmcgill.github.io/icml2017-rlworkshop/">ICML’2017 RL late breaking results event</a>, at ICML, Sydney, Australia, 2017</i></p>
				</p>
			</div>
		</div>
		</div>
	</body>
</html>